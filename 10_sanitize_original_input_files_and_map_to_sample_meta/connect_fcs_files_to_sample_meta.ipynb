{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deprecated\n",
    "\n",
    "It turned out much more time consumig to parse filenames (created by various people) and connect them to single database of entries.\n",
    "New strategy is to keep metadata info per folder in `sample_meta.csv` and rather update / create this file when new samples are added to a folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import csv\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = pathlib.Path('..')\n",
    "fcs_dir = root / 'input_data' / 'original'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a strong assumption that everything not from gut (SCS) is from PBMCs\n",
    "sm =[dict(path = x.relative_to(root),\n",
    "      filename = x.stem,\n",
    "      biosource = 'SCS' if 'SCS' in str(x.parent) else 'PBMC'\n",
    "     ) for x in fcs_dir.glob('**/*.fcs')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For now, some fcs files without match are dropped\n",
    "\n",
    "The flu samples are not yet in Asbjorns sample list and not critical do current workflow.\n",
    "Therefore, instead of spending time on adding them now, I wait until Asbjorn has added them (or until I have done what I should for the paper)\n",
    "\n",
    "an example of such a sample is this `../input_data/original/Autoimmune control and Flu CD4/Autoimmune and control/BBS_1189 All CD4.fcs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import regex\n",
    "auto_phenotype = 'AutoPhenotype'\n",
    "ced_status = dict(U='untreated', T='GFD', H='control', C='Challenge')\n",
    "sample_category = dict(\n",
    "    pre = 'full',\n",
    "    pos = 'tetramer+',\n",
    "    neg = 'tetramer-',\n",
    "    all = 'full',\n",
    "    phenotype = auto_phenotype\n",
    ")    \n",
    "\n",
    "pat = dict(\n",
    "    cdonor = regex.compile(r'^(?<CeD_status>.?)(?<donor>CD\\d+).*(?<sample_cat>PRE|POS|NEG)', regex.IGNORECASE),\n",
    "    ctrl_date = regex.compile(r'^(?<date>\\d+) (?<donor>BC11)'),\n",
    "    ctrl = regex.compile(r'^(?<donor>BC\\d+)'),\n",
    "    flu = regex.compile(r'^(?<donor>[^ ]+) Flu.*(?<sample_cat>Phenotype|All)', regex.IGNORECASE)\n",
    ")\n",
    "\n",
    "assert pat['cdonor'].match('UCD1423P.A Tetramer POS.fcs')\n",
    "\n",
    "def find_match(patterns, filename):\n",
    "    for pat_name, p in patterns.items():\n",
    "        m = p.search(filename)\n",
    "        if m is not None:\n",
    "            return (pat_name, m)\n",
    "    else:\n",
    "        raise LookupError(filename)\n",
    "        \n",
    "def generate_entry(p, m):\n",
    "    def parse_cdonor(d):\n",
    "        return dict(\n",
    "            ced = ced_status[d['CeD_status']],\n",
    "            donor = d['donor'],\n",
    "            category = sample_category[d['sample_cat'].lower()]\n",
    "        )\n",
    "    \n",
    "    def parse_flu(d):\n",
    "        return dict(\n",
    "            ced = 'Flu',\n",
    "            donor = d['donor'],\n",
    "            category = sample_category[d['sample_cat'].lower()]\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def parse_cdonor(d):\n",
    "        return dict(\n",
    "            ced = ced_status[d['CeD_status']],\n",
    "            donor = d['donor'],\n",
    "            category = sample_category[d['sample_cat'].lower()]\n",
    "        )\n",
    "    \n",
    "    def parse_ctrl(d):\n",
    "        return dict(\n",
    "            ced = 'control',\n",
    "            donor = d['donor']\n",
    "        )\n",
    "    def parse_date_ctrl(d):\n",
    "        return dict(\n",
    "            ced = 'control',\n",
    "            donor = d['donor'],\n",
    "            date = d['date'],\n",
    "            extra_info = 'sample is PBMC date ctrl'\n",
    "        )\n",
    "    default_d = dict(\n",
    "        date = 'Not specified',\n",
    "        category = sample_category['pre']\n",
    "    )\n",
    "    if p == 'cdonor':\n",
    "        d=  parse_cdonor(m.groupdict())\n",
    "    elif p == 'ctrl':\n",
    "        d = parse_ctrl(m.groupdict())\n",
    "    elif p == 'ctrl_date':\n",
    "        d = parse_date_ctrl(m.groupdict())\n",
    "    elif p == 'flu':\n",
    "        d = parse_flu(m.groupdict())\n",
    "    default_d.update(d)\n",
    "    return default_d\n",
    "\n",
    "def parse_filenames(xs):\n",
    "    extra_matches = {\n",
    "        'CD1222 DM type1 All CD4': dict(\n",
    "            ced = 'T1DB',\n",
    "            category = 'full',\n",
    "            donor = 'CD1222'\n",
    "        ),\n",
    "        'CD1222 DM type1 CD Phenotype': dict(\n",
    "            ced = 'T1DB',\n",
    "            category = auto_phenotype,\n",
    "            donor = 'CD1222'\n",
    "        ),\n",
    "        'BBS_3 All CD4': dict(\n",
    "            ced = 'SSC',\n",
    "            category = 'full',\n",
    "            donor = 'BBS_3'\n",
    "        ),\n",
    "        'BBS_3 CD4 Phenotype': dict(\n",
    "            ced = 'SSC',\n",
    "            category = auto_phenotype,\n",
    "            donor = 'BBS_3'\n",
    "        ),\n",
    "        'BBS_1189 All CD4': dict(\n",
    "            ced = 'SLE',\n",
    "            category = 'full',\n",
    "            donor = 'BBS_1189'\n",
    "        ),\n",
    "        'Control_BCN11 All CD4': dict(\n",
    "            ced = 'control',\n",
    "            category = 'full',\n",
    "            donor = 'BC11'\n",
    "        )\n",
    "    }\n",
    "    for v in extra_matches.values():\n",
    "        v['date'] = 'not specified'\n",
    "        v['biosource'] = 'PBMC'\n",
    "    for x in xs:\n",
    "        fname = x['filename']\n",
    "        try:\n",
    "            pattern, m = find_match(pat, fname)\n",
    "        except LookupError:\n",
    "            if fname in extra_matches:\n",
    "                d = dict(extra_matches[fname])\n",
    "            else:\n",
    "                print('Unable to parse:', fname)\n",
    "                continue\n",
    "        else:            \n",
    "            d = generate_entry(pattern, m)\n",
    "        d.update(x)\n",
    "        if d.get('extra_info', False) == 'sample is PBMC date ctrl':\n",
    "            d['biosource'] = 'PBMC'\n",
    "        yield d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing filenames should not give parse errors. Check entries if that is the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_filenames = list(parse_filenames(sm))\n",
    "#print(parsed_filenames[0])\n",
    "# for x in [x['filename'] for x in parsed_filenames if 'CD1535' == x['donor']]:\n",
    "#    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input_data/original/sample_meta.csv') as f:\n",
    "    sample_metas = list(csv.DictReader(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "class NoMatchError(LookupError):\n",
    "    pass\n",
    "class MultipleMatchesError(LookupError):\n",
    "    pass\n",
    "\n",
    "\n",
    "def find_match(parsed_filename, sample_meta):\n",
    "    donor_xs = [x for x in sample_meta if parsed_filename['donor'] in x['sample']]\n",
    "    bio_xs = [x for x in donor_xs if parsed_filename['biosource'] == x['biosource']]\n",
    "    xs = bio_xs\n",
    "    if len(xs) == 0:\n",
    "        print('No match for {donor} | {biosource} | {filename}'.format(**parsed_filename))\n",
    "        print('DONOR_XS:')\n",
    "        print(donor_xs)\n",
    "        print('BIO_XS:')\n",
    "        pprint(bio_xs)\n",
    "        print()\n",
    "        raise NoMatchError(f'No match for {parsed_filename}')\n",
    "    elif len(xs) > 1 and len([x for x in xs if parsed_filename['ced'] == x['Disease Status']]) == 1:\n",
    "        xs = [x for x in xs if parsed_filename['ced'] == x['Disease Status']]\n",
    "    elif len(xs) > 1:\n",
    "        print(f'Multiple matches for {parsed_filename}')\n",
    "        pprint(xs)\n",
    "        print()\n",
    "        raise MultipleMatchesError(f'Multiple matches for {parsed_filename}')\n",
    "    assert len(xs) == 1\n",
    "    return copy(xs[0])\n",
    "\n",
    "def forgivable_matching(pfs, sm):\n",
    "    xs = []\n",
    "    for x in pfs:\n",
    "        try:\n",
    "            y = find_match(x, sm)\n",
    "            y['filename'] = x['filename']\n",
    "            y['path'] = x['path']\n",
    "            y['donor'] = x['donor']\n",
    "            y['sample_category'] = x['category']\n",
    "            xs.append(y)\n",
    "        except NoMatchError or MultipleMatchesError as e:\n",
    "            print('Error handling', e)\n",
    "            print()\n",
    "    return xs\n",
    "        \n",
    "    \n",
    "samples_with_filenames = forgivable_matching(parsed_filenames, sample_metas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('sample', 'CCD1535'),\n",
       "              ('biosource', 'PBMC'),\n",
       "              ('Disease', 'Ced'),\n",
       "              ('Disease Status', 'Challenge'),\n",
       "              ('Instrument', 'Helios Davis'),\n",
       "              ('Experimet Date', ''),\n",
       "              ('Note', '{“day”: 6}'),\n",
       "              ('filename', 'CCD1535_day6_tetramer_POS'),\n",
       "              ('path',\n",
       "               PosixPath('input_data/original/PBMC/gluten_challenge_CD1535_CD4/CCD1535_day6_tetramer_POS.fcs')),\n",
       "              ('donor', 'CD1535'),\n",
       "              ('sample_category', 'tetramer+')]),\n",
       " OrderedDict([('sample', 'TCD1535'),\n",
       "              ('biosource', 'PBMC'),\n",
       "              ('Disease', 'Ced'),\n",
       "              ('Disease Status', 'GFD'),\n",
       "              ('Instrument', 'Helios Davis'),\n",
       "              ('Experimet Date', ''),\n",
       "              ('Note', ''),\n",
       "              ('filename', 'TCD1535_tetramer_NEG'),\n",
       "              ('path',\n",
       "               PosixPath('input_data/original/PBMC/gluten_challenge_CD1535_CD4/TCD1535_tetramer_NEG.fcs')),\n",
       "              ('donor', 'CD1535'),\n",
       "              ('sample_category', 'tetramer-')]),\n",
       " OrderedDict([('sample', 'CCD1535'),\n",
       "              ('biosource', 'PBMC'),\n",
       "              ('Disease', 'Ced'),\n",
       "              ('Disease Status', 'Challenge'),\n",
       "              ('Instrument', 'Helios Davis'),\n",
       "              ('Experimet Date', ''),\n",
       "              ('Note', '{“day”: 6}'),\n",
       "              ('filename', 'CCD1535_day6_tetramer_NEG'),\n",
       "              ('path',\n",
       "               PosixPath('input_data/original/PBMC/gluten_challenge_CD1535_CD4/CCD1535_day6_tetramer_NEG.fcs')),\n",
       "              ('donor', 'CD1535'),\n",
       "              ('sample_category', 'tetramer-')]),\n",
       " OrderedDict([('sample', 'TCD1535'),\n",
       "              ('biosource', 'PBMC'),\n",
       "              ('Disease', 'Ced'),\n",
       "              ('Disease Status', 'GFD'),\n",
       "              ('Instrument', 'Helios Davis'),\n",
       "              ('Experimet Date', ''),\n",
       "              ('Note', ''),\n",
       "              ('filename', 'TCD1535_tetramer_POS'),\n",
       "              ('path',\n",
       "               PosixPath('input_data/original/PBMC/gluten_challenge_CD1535_CD4/TCD1535_tetramer_POS.fcs')),\n",
       "              ('donor', 'CD1535'),\n",
       "              ('sample_category', 'tetramer+')])]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in samples_with_filenames if x['donor'] == 'CD1535']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We got 91 fcs files and 90 samples annotated in DB. We have 91 matches.\n"
     ]
    }
   ],
   "source": [
    "print(f\"We got {len(parsed_filenames)} fcs files and {len(sample_metas)} samples annotated in DB. We have {len(samples_with_filenames)} matches.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new sample_db that includes file names\n",
    "\n",
    "Possibly create copies with sane filenames, but don't bother if this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input_data/renamed/fcs_matched_samples.csv', 'w') as f: \n",
    "    writer = csv.DictWriter(f, samples_with_filenames[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(samples_with_filenames)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
